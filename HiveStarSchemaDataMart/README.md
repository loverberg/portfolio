# Hive.Create DataMart

#### Задача: Обеспечить постоянный доступ к холодным данным, создать схему `Star`, создать витрину вида:

| Payment type | Date |	Tips average amount | Passengers total |
| :------------| :--- | :------------------ | :--------------- |
|Cash|	2020-01-31|	999.99|	112|

#### input-data: file.csv (семпл данных Нью-Йоркского такси за 2020. Это открытый датасет, который лежит на amazon `s3`. Подробнее здесь [Trip Record Data][1]):
1,2020-04-01 00:41:22,2020-04-01 01:01:53,1,1.20,1,N,41,24,2,5.5,0.5,0.5,0,0,0.3,6.8,0

### Ход работы:
1. _Разворачивание кластера Hadoop_ с использованием облачного решения Yandex.Cloud:
  - Имплементация сервера на базе операционной системы Ubuntu (инсталировано: `HDFS` v. 3.2.2, `YARN` v. 3.2.2, `MapReduce` v.3.2.2, `Hive` v. 3.1.2, `TEZ` v. 0.10.0);
    NameNode: 1x4Cores&16RAM, DataNode: 3x4Cores&16RAM; Subcluster.Compute: 2x4Cores&16RAM.
  - Создание бакета на `s3`.
2. *Копирование данных* на созданный бакет `s3` с помощью утилиты distcp, которая позволяет выполнить распределенное копирование данных между распределенными файловыми системами, использовал протокол - `s3a`. Это публичный бакет, возможен доступ без авторизации.
3. *Определение иерархии Hive:*
---
       - Database (yellow_taxi)
                - Table (payment - dimension table, input_data - fact table(input format), trip_part - fact table) 
                       - Partition (date) *опционально
                       - Bucket (не использую, т.к. не планирую использовать SMB (Sort Merge Bucket) Join) *опционально         
                - View (не планирую)
                - Materialized view (в качестве Data Mart)
                
       *утилита доступа - Hive CLI*
---
4. При создании Database (базы данных).
5. 
      
При создании Database (базы данных), Table (таблицы) или Partition (партиции) мы можем явно указывать расположение данных на HDFS.

Партиции — разбиение данных в таблице по какому-либо принципу. Например, по дням. Таким образом поиск нужных данных в большой таблице будет занимать меньше времени. Партиции также можно делать вложенными. На примере продаж продуктовой сети: 1 уровень — филиал,  2 уровень — дата продажи. 

Количество Buckets (бакеты) указывается на момент создания таблицы. Требуется указать по каким полям мы хотим бакетировать таблицу, с каким количеством бакетов и сортировку (опционально). Бакеты позволяют делать эффективный join таблиц, но требуют внимательного обслуживания. 

View (представления) не оптимизируют запрос, а только добавляют удобства в работе с большими запросами.

Materialized view (материализованное представление) — условная витрина, строящаяся по какому-либо запросу. Материализованные представления пришли на смену индексам, так как начиная с версии Hive 3 их нет (они не получили широкого применения).  

Hive CLI представляет собой две утилиты (Hive и Beeline). С точки зрения архитектурной целостности Beeline является более правильным средством.  

В общем случае создание таблицы в Hive похоже на создание таблицы в любой реляционной БД. Мы можем задавать комментарии полям, либо таблице в целом. 

Выражение PARTITIONED BY в нашем случае партиционирует таблицу по двум уровням. Первый уровень — поле dt, второй уровень — country. Стоит отметить, что значения этих полей в данных на HDFS не будет. Информация о партициях хранится в Metastore.

CLUSTERED BY позволяет бакетировать таблицу — разбивать данные на бакеты. В данном случае создается 32 бакета по полю userid. Также внутри бакета можем задавать сортировку.

ROW FORMAT DELIMETED указывает формат, в котором мы будем хранить таблицу. В нашем случае это будет SEQUENCEFILE и внутри него мы храним по паттерну, что поля разделяются символом ';', сложные типы данных (коллекции) разделяются ',' и тип данных MAP (словарь) разделяется '\'.

Создание внешней таблицы в Hive тоже похоже на создание такой таблицы в обычных реляционных БД.

Мы можем создать внешнюю таблицу на данных, которые лежат не в папке, в котором расположен Hive, а где-то снаружи.

Главной причиной создания внешних таблиц является их поведение при удалении. При удалении обычной managed таблицы через команду DROP TABLE, Hive удаляет всю информацию о ней в Metastore и удаляет данные этой таблицы на HDFS. И проблема в том, что не во всех случаях данные можно восстановить обратно. Но при удалении внешней таблицы, удаляются только метаданные о ней. Сами данные не удаляются и не производится попыток их удаления. 

Reduce side Join

Для обеих таблиц запускаются mappers. Mappers, работающие с таблицей клиентов будет на выходе предоставлять пару ключ-значение. В качестве ключа будет использоваться id, в качестве значения - name. Mappers, работающие с таблицей продаж будут использовать фильтр и на выходе из них мы получаем ключ client_id и значение - amount. Эти записи будут приходить на reducer, где мы уже получаем id, который для обеих таблиц по значению является одним и тем же, name из mappers, которые работали с таблицей клиентов и amount от mappers, работающих с таблицей продаж. Так как все ключи гарантированно на одном reducer, мы можем провести агрегацию по этим ключам и получить результат. 

LOCATION - обязательный параметр при создании внешних таблиц.  


[1]:https://registry.opendata.aws/nyc-tlc-trip-records-pds/
