## Учет и трекинг моделей с MLFlow

#### Проблематика: 
Работа над автоматизацией процессов страховой компании. 
Необходимо разработать модель для классификации водителей, по предсказанию вероятности аварии 
водителя в будущем году, на который водитель планирует приобрести страховку. 
Для этого использована собранная статистика по клиентам.

#### Задачи: 
1. Реализовать классификатор водителей PySparkFit.py, добавить разметку 
эксперимента для трекинга процесса обучения модели в MLFlow.

___
    Требования к логированию эксперимента:
        
        Метрики: 

            f1, weightedPrecision, weightedRecall, accuracy
    
         Параметры: 
    
            input_columns - список колонок исходного датасета (Пример: ['col1, 'col2'])
            
            maxDepth - параметр максимальной глубины обученной модели
            
            maxIter - параметр максимального числа итераций обучения модели
            
            maxBins - параметр максимального числа ветвлений
            
            target - целевая переменная для предсказаний
            
            features - список колонок использованных для векторизации (Пример: ['col1, 'col2'])
            
            stage_0 - Тип трансформера первого стейджа пайплайна (obj.__class__.__name__)
            
            stage_1 - Тип трансформера второго стейджа пайплайна (obj.__class__.__name__)
            
            stage_2 - Тип трансформера третьего стейджа пайплайна (obj.__class__.__name__)
            
            stage_3 - Тип трансформера четвертого стейджа пайплайна (obj.__class__.__name__)
___
2. Реализовать задачу PySparkPredict.py, которая будет загружать *Production* модель 
из MLFlow, применять к данным и сохранять полученный датасет с предсказаниями
в дерикторию результатов.

#### Структура исходных данных

|        Поле         | 	Описание                                                                     |
|:-------------------:|:------------------------------------------------------------------------------|
|      driver_id      | 	уникальный идентификатор водителя                                            |
|         age         | 	возраст водителя на момент анализа                                           |
|        sex	         | пол водителя                                                                  |
|      car_class      | класс машины водителя                                                         |
| driving_experience	 | опыт вождения                                                                 |
| speeding_penalties	 | количество штрафов за превышение скорости в течении года                      |
| parking_penalties	  | 	количество штрафов за неправильную парковку в течении года                   |
|   total_car_accident   | число аварий за весь опыт вождения                                            |
|       has_car_accident       | идентификатор аварии в текущем году (целевой признак [0/1])                                    |


### Ход работы:
1. Создание Pipeline модели и ее версионирование 

    Реализация: [*PySparkMLFit.py*][] 
---

    python PySparkFit.py  --train=data/train.parquet --test=data/test.parquet

#### OR

    spark-submit PySparkFit.py  --data/train=train.parquet --test=data/test.parquet
---

2. Выбор лучшей модели и назначение ее как *Production* модели

3. Загрузка и запуск *Production* модели
    
    Реализация: [*PySparkPredict.py*][] 


---
    python PySparkPredict.py  --data=data/data.parquet --result=result
#### OR
    spark-submit PySparkPredict.py  --data=data/data.parquet --result=result
---


[1]:
[2]:
